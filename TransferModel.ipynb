{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_finetune import make_model\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorboardX import SummaryWriter \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(299,299)\n",
    "LR = 0.001    \n",
    "BATCH_SIZE=8\n",
    "EPOCHS=1000\n",
    "EARLY_STOP_Threshold=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def make_classifier(in_features, num_classes):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "\n",
    "model = make_model('xception', num_classes=120, pretrained=True, input_size=(299, 299), classifier_factory=make_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XceptionWrapper(\n",
       "  (_features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Block(\n",
       "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): SeparableConv2d(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (rep): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (17): SeparableConv2d(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (18): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): SeparableConv2d(\n",
       "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (20): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_classifier): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=240, bias=True)\n",
       "    (1): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=240, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 149, 149]             864\n",
      "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
      "              ReLU-3         [-1, 32, 149, 149]               0\n",
      "            Conv2d-4         [-1, 64, 147, 147]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 147, 147]             128\n",
      "            Conv2d-6         [-1, 64, 147, 147]             576\n",
      "            Conv2d-7        [-1, 128, 147, 147]           8,192\n",
      "   SeparableConv2d-8        [-1, 128, 147, 147]               0\n",
      "       BatchNorm2d-9        [-1, 128, 147, 147]             256\n",
      "             ReLU-10        [-1, 128, 147, 147]               0\n",
      "             ReLU-11        [-1, 128, 147, 147]               0\n",
      "           Conv2d-12        [-1, 128, 147, 147]           1,152\n",
      "           Conv2d-13        [-1, 128, 147, 147]          16,384\n",
      "  SeparableConv2d-14        [-1, 128, 147, 147]               0\n",
      "      BatchNorm2d-15        [-1, 128, 147, 147]             256\n",
      "        MaxPool2d-16          [-1, 128, 74, 74]               0\n",
      "           Conv2d-17          [-1, 128, 74, 74]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 74, 74]             256\n",
      "            Block-19          [-1, 128, 74, 74]               0\n",
      "             ReLU-20          [-1, 128, 74, 74]               0\n",
      "           Conv2d-21          [-1, 128, 74, 74]           1,152\n",
      "           Conv2d-22          [-1, 256, 74, 74]          32,768\n",
      "  SeparableConv2d-23          [-1, 256, 74, 74]               0\n",
      "      BatchNorm2d-24          [-1, 256, 74, 74]             512\n",
      "             ReLU-25          [-1, 256, 74, 74]               0\n",
      "             ReLU-26          [-1, 256, 74, 74]               0\n",
      "           Conv2d-27          [-1, 256, 74, 74]           2,304\n",
      "           Conv2d-28          [-1, 256, 74, 74]          65,536\n",
      "  SeparableConv2d-29          [-1, 256, 74, 74]               0\n",
      "      BatchNorm2d-30          [-1, 256, 74, 74]             512\n",
      "        MaxPool2d-31          [-1, 256, 37, 37]               0\n",
      "           Conv2d-32          [-1, 256, 37, 37]          32,768\n",
      "      BatchNorm2d-33          [-1, 256, 37, 37]             512\n",
      "            Block-34          [-1, 256, 37, 37]               0\n",
      "             ReLU-35          [-1, 256, 37, 37]               0\n",
      "           Conv2d-36          [-1, 256, 37, 37]           2,304\n",
      "           Conv2d-37          [-1, 728, 37, 37]         186,368\n",
      "  SeparableConv2d-38          [-1, 728, 37, 37]               0\n",
      "      BatchNorm2d-39          [-1, 728, 37, 37]           1,456\n",
      "             ReLU-40          [-1, 728, 37, 37]               0\n",
      "             ReLU-41          [-1, 728, 37, 37]               0\n",
      "           Conv2d-42          [-1, 728, 37, 37]           6,552\n",
      "           Conv2d-43          [-1, 728, 37, 37]         529,984\n",
      "  SeparableConv2d-44          [-1, 728, 37, 37]               0\n",
      "      BatchNorm2d-45          [-1, 728, 37, 37]           1,456\n",
      "        MaxPool2d-46          [-1, 728, 19, 19]               0\n",
      "           Conv2d-47          [-1, 728, 19, 19]         186,368\n",
      "      BatchNorm2d-48          [-1, 728, 19, 19]           1,456\n",
      "            Block-49          [-1, 728, 19, 19]               0\n",
      "             ReLU-50          [-1, 728, 19, 19]               0\n",
      "           Conv2d-51          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-52          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-53          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-54          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-55          [-1, 728, 19, 19]               0\n",
      "             ReLU-56          [-1, 728, 19, 19]               0\n",
      "           Conv2d-57          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-58          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-59          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-60          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-61          [-1, 728, 19, 19]               0\n",
      "             ReLU-62          [-1, 728, 19, 19]               0\n",
      "           Conv2d-63          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-64          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-65          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-66          [-1, 728, 19, 19]           1,456\n",
      "            Block-67          [-1, 728, 19, 19]               0\n",
      "             ReLU-68          [-1, 728, 19, 19]               0\n",
      "           Conv2d-69          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-70          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-71          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-72          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-73          [-1, 728, 19, 19]               0\n",
      "             ReLU-74          [-1, 728, 19, 19]               0\n",
      "           Conv2d-75          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-76          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-77          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-78          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-79          [-1, 728, 19, 19]               0\n",
      "             ReLU-80          [-1, 728, 19, 19]               0\n",
      "           Conv2d-81          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-82          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-83          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-84          [-1, 728, 19, 19]           1,456\n",
      "            Block-85          [-1, 728, 19, 19]               0\n",
      "             ReLU-86          [-1, 728, 19, 19]               0\n",
      "           Conv2d-87          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-88          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-89          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-90          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-91          [-1, 728, 19, 19]               0\n",
      "             ReLU-92          [-1, 728, 19, 19]               0\n",
      "           Conv2d-93          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-94          [-1, 728, 19, 19]         529,984\n",
      "  SeparableConv2d-95          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-96          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-97          [-1, 728, 19, 19]               0\n",
      "             ReLU-98          [-1, 728, 19, 19]               0\n",
      "           Conv2d-99          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-100          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-101          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-102          [-1, 728, 19, 19]           1,456\n",
      "           Block-103          [-1, 728, 19, 19]               0\n",
      "            ReLU-104          [-1, 728, 19, 19]               0\n",
      "          Conv2d-105          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-106          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-107          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-108          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-109          [-1, 728, 19, 19]               0\n",
      "            ReLU-110          [-1, 728, 19, 19]               0\n",
      "          Conv2d-111          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-112          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-113          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-114          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-115          [-1, 728, 19, 19]               0\n",
      "            ReLU-116          [-1, 728, 19, 19]               0\n",
      "          Conv2d-117          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-118          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-119          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-120          [-1, 728, 19, 19]           1,456\n",
      "           Block-121          [-1, 728, 19, 19]               0\n",
      "            ReLU-122          [-1, 728, 19, 19]               0\n",
      "          Conv2d-123          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-124          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-125          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-126          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-127          [-1, 728, 19, 19]               0\n",
      "            ReLU-128          [-1, 728, 19, 19]               0\n",
      "          Conv2d-129          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-130          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-131          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-132          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-133          [-1, 728, 19, 19]               0\n",
      "            ReLU-134          [-1, 728, 19, 19]               0\n",
      "          Conv2d-135          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-136          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-137          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-138          [-1, 728, 19, 19]           1,456\n",
      "           Block-139          [-1, 728, 19, 19]               0\n",
      "            ReLU-140          [-1, 728, 19, 19]               0\n",
      "          Conv2d-141          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-142          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-143          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-144          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-145          [-1, 728, 19, 19]               0\n",
      "            ReLU-146          [-1, 728, 19, 19]               0\n",
      "          Conv2d-147          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-148          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-149          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-150          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-151          [-1, 728, 19, 19]               0\n",
      "            ReLU-152          [-1, 728, 19, 19]               0\n",
      "          Conv2d-153          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-154          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-155          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-156          [-1, 728, 19, 19]           1,456\n",
      "           Block-157          [-1, 728, 19, 19]               0\n",
      "            ReLU-158          [-1, 728, 19, 19]               0\n",
      "          Conv2d-159          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-160          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-161          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-162          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-163          [-1, 728, 19, 19]               0\n",
      "            ReLU-164          [-1, 728, 19, 19]               0\n",
      "          Conv2d-165          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-166          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-167          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-168          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-169          [-1, 728, 19, 19]               0\n",
      "            ReLU-170          [-1, 728, 19, 19]               0\n",
      "          Conv2d-171          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-172          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-173          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-174          [-1, 728, 19, 19]           1,456\n",
      "           Block-175          [-1, 728, 19, 19]               0\n",
      "            ReLU-176          [-1, 728, 19, 19]               0\n",
      "          Conv2d-177          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-178          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-179          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-180          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-181          [-1, 728, 19, 19]               0\n",
      "            ReLU-182          [-1, 728, 19, 19]               0\n",
      "          Conv2d-183          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-184          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-185          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-186          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-187          [-1, 728, 19, 19]               0\n",
      "            ReLU-188          [-1, 728, 19, 19]               0\n",
      "          Conv2d-189          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-190          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-191          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-192          [-1, 728, 19, 19]           1,456\n",
      "           Block-193          [-1, 728, 19, 19]               0\n",
      "            ReLU-194          [-1, 728, 19, 19]               0\n",
      "          Conv2d-195          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-196          [-1, 728, 19, 19]         529,984\n",
      " SeparableConv2d-197          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-198          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-199          [-1, 728, 19, 19]               0\n",
      "            ReLU-200          [-1, 728, 19, 19]               0\n",
      "          Conv2d-201          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-202         [-1, 1024, 19, 19]         745,472\n",
      " SeparableConv2d-203         [-1, 1024, 19, 19]               0\n",
      "     BatchNorm2d-204         [-1, 1024, 19, 19]           2,048\n",
      "       MaxPool2d-205         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-206         [-1, 1024, 10, 10]         745,472\n",
      "     BatchNorm2d-207         [-1, 1024, 10, 10]           2,048\n",
      "           Block-208         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-209         [-1, 1024, 10, 10]           9,216\n",
      "          Conv2d-210         [-1, 1536, 10, 10]       1,572,864\n",
      " SeparableConv2d-211         [-1, 1536, 10, 10]               0\n",
      "     BatchNorm2d-212         [-1, 1536, 10, 10]           3,072\n",
      "          Conv2d-213         [-1, 1536, 10, 10]          13,824\n",
      "          Conv2d-214         [-1, 2048, 10, 10]       3,145,728\n",
      " SeparableConv2d-215         [-1, 2048, 10, 10]               0\n",
      "     BatchNorm2d-216         [-1, 2048, 10, 10]           4,096\n",
      "AdaptiveAvgPool2d-217           [-1, 2048, 1, 1]               0\n",
      "          Linear-218                  [-1, 240]         491,760\n",
      "     BatchNorm1d-219                  [-1, 240]             480\n",
      "            ReLU-220                  [-1, 240]               0\n",
      "          Linear-221                  [-1, 120]          28,920\n",
      "================================================================\n",
      "Total params: 21,328,112\n",
      "Trainable params: 21,328,112\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 785.21\n",
      "Params size (MB): 81.36\n",
      "Estimated Total Size (MB): 867.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model.cuda(), (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "train_transforms = transforms.Compose([transforms.Resize(IMAGE_SIZE),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      \n",
    "                                      transforms.ColorJitter(),\n",
    "                                      transforms.RandomRotation(30),\n",
    "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      \n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(IMAGE_SIZE),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(IMAGE_SIZE),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the training and test datasets\n",
    "train_data = datasets.ImageFolder('data/train', transform=train_transforms)\n",
    "val_data = datasets.ImageFolder('data/val',transform=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dir=train_data.class_to_idx\n",
    "#print(class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "classes = list(class_dir.keys())\n",
    "mean , std = torch.tensor([0.485, 0.456, 0.406]),torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def denormalize(image):\n",
    "  image = transforms.Normalize(-mean/std,1/std)(image) #denormalize\n",
    "  image = image.permute(1,2,0) #Changing from 3x224x224 to 224x224x3\n",
    "  image = torch.clamp(image,0,1)\n",
    "  return image\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = denormalize(img) \n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader: 1973\n",
      "val_loader: 450\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True)\n",
    "print(\"train_loader:\",len(train_loader))\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE,shuffle=True)\n",
    "print(\"val_loader:\",len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XceptionWrapper(\n",
      "  (_features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Block(\n",
      "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): SeparableConv2d(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): SeparableConv2d(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): Block(\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): Block(\n",
      "      (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (rep): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (17): SeparableConv2d(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (18): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): SeparableConv2d(\n",
      "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (20): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=240, bias=True)\n",
      "    (1): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=240, out_features=120, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "print(model)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "#optimizer = torch.optim.RMSprop(cnn.parameters())   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2021_01_07-20_31_01'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "model_name=run_logdir.split(\"/\")[-1]\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:16<00:00,  5.25it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  , train loss :  4.745896166106339 , train_accuracy: 1.7  , valid loss : 4.578082690238952 , val_accuracy: 1.67\n",
      "save model, current best val_accuracy: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:07<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  , train loss :  4.403734483814971 , train_accuracy: 2.95  , valid loss : 4.365975757704841 , val_accuracy: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:09,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:45<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2  , train loss :  4.286642393780885 , train_accuracy: 4.11  , valid loss : 4.283263317214118 , val_accuracy: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:10,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:44<00:00,  5.73it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3  , train loss :  4.2145597417361085 , train_accuracy: 4.22  , valid loss : 4.228917011155023 , val_accuracy: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:42<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4  , train loss :  4.156142563744034 , train_accuracy: 4.79  , valid loss : 4.152307096587287 , val_accuracy: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:04,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5  , train loss :  4.00627447708273 , train_accuracy: 5.79  , valid loss : 3.9850289323594836 , val_accuracy: 6.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:06,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 6.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6  , train loss :  3.810696746106459 , train_accuracy: 7.89  , valid loss : 3.80162294599745 , val_accuracy: 8.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<05:56,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 8.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7  , train loss :  3.6858621290317997 , train_accuracy: 9.8  , valid loss : 3.674140354262458 , val_accuracy: 9.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:03,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 9.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8  , train loss :  3.5705615636611725 , train_accuracy: 10.72  , valid loss : 3.610132368935479 , val_accuracy: 10.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:07,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 10.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9  , train loss :  3.4116901496160965 , train_accuracy: 13.32  , valid loss : 3.4610679483413698 , val_accuracy: 12.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:06,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 12.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10  , train loss :  3.2736502954492823 , train_accuracy: 14.92  , valid loss : 3.3089305464426677 , val_accuracy: 13.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:15,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 13.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11  , train loss :  3.151006791141219 , train_accuracy: 17.06  , valid loss : 3.2795512178209094 , val_accuracy: 14.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:22,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 14.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12  , train loss :  3.081050160704959 , train_accuracy: 17.74  , valid loss : 3.2415892963939243 , val_accuracy: 16.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:12,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 16.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13  , train loss :  3.0118450519211946 , train_accuracy: 19.6  , valid loss : 3.143849498960707 , val_accuracy: 17.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 17.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14  , train loss :  2.962388872518551 , train_accuracy: 20.56  , valid loss : 3.1561494000752766 , val_accuracy: 17.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15  , train loss :  2.896212814727417 , train_accuracy: 21.34  , valid loss : 3.110415157477061 , val_accuracy: 18.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<05:52,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 18.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  16  , train loss :  2.82822743570618 , train_accuracy: 22.76  , valid loss : 3.0218755729993183 , val_accuracy: 20.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<05:52,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 20.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.83it/s]\n",
      "  0%|          | 1/1973 [00:00<05:38,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17  , train loss :  2.792148658928441 , train_accuracy: 23.24  , valid loss : 3.0092999341752793 , val_accuracy: 19.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  18  , train loss :  2.713296422200463 , train_accuracy: 24.72  , valid loss : 2.985661091539595 , val_accuracy: 21.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<05:49,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 21.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:46<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  19  , train loss :  2.676281605997393 , train_accuracy: 25.81  , valid loss : 2.896484646267361 , val_accuracy: 22.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:23,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 22.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  20  , train loss :  2.612349528604243 , train_accuracy: 26.73  , valid loss : 2.8713919626341924 , val_accuracy: 22.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 22.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  21  , train loss :  2.5125164281688073 , train_accuracy: 28.35  , valid loss : 2.7850259224573772 , val_accuracy: 24.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:03,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 24.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:39<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  22  , train loss :  2.4060978168346967 , train_accuracy: 31.52  , valid loss : 2.719565830760532 , val_accuracy: 26.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:11,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 26.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  23  , train loss :  2.324350468581587 , train_accuracy: 32.44  , valid loss : 2.682601016097599 , val_accuracy: 27.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:14,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 27.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  24  , train loss :  2.264321516777854 , train_accuracy: 34.42  , valid loss : 2.680494812859429 , val_accuracy: 28.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:19,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 28.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  25  , train loss :  2.181957296669668 , train_accuracy: 36.17  , valid loss : 2.605824468400743 , val_accuracy: 29.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<05:52,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 29.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.83it/s]\n",
      "  0%|          | 1/1973 [00:00<05:31,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  26  , train loss :  2.14539528050209 , train_accuracy: 37.89  , valid loss : 2.6081701425711312 , val_accuracy: 29.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  27  , train loss :  2.044620782569437 , train_accuracy: 39.29  , valid loss : 2.585956199698978 , val_accuracy: 31.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<05:35,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 31.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:38<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  28  , train loss :  1.9791188016576349 , train_accuracy: 40.92  , valid loss : 2.6059053349494934 , val_accuracy: 31.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:17,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 31.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:42<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  29  , train loss :  1.9515381361400306 , train_accuracy: 41.51  , valid loss : 2.561903702682919 , val_accuracy: 33.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:18,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 33.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:43<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  30  , train loss :  1.9025309515419444 , train_accuracy: 43.29  , valid loss : 2.514534538057115 , val_accuracy: 34.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 34.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [07:08<00:00,  4.61it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  31  , train loss :  1.8095540521987847 , train_accuracy: 45.23  , valid loss : 2.621728361050288 , val_accuracy: 33.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [07:24<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  32  , train loss :  1.7611868225264227 , train_accuracy: 46.68  , valid loss : 2.5384230497148303 , val_accuracy: 35.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 35.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [07:23<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  33  , train loss :  1.7453016705352533 , train_accuracy: 47.29  , valid loss : 2.4702437346511417 , val_accuracy: 36.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 36.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:41<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  34  , train loss :  1.6893817278601324 , train_accuracy: 48.24  , valid loss : 2.4955158176687027 , val_accuracy: 37.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1973 [00:00<06:01,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 37.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:51<00:00,  5.62it/s]\n",
      "  0%|          | 1/1973 [00:00<06:01,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  35  , train loss :  1.6228334398367565 , train_accuracy: 50.29  , valid loss : 2.5516058366828496 , val_accuracy: 36.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:21<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  36  , train loss :  1.5868358907307334 , train_accuracy: 51.32  , valid loss : 2.431609226067861 , val_accuracy: 38.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 38.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:26<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  37  , train loss :  1.5614239642493013 , train_accuracy: 51.98  , valid loss : 2.4030416227711573 , val_accuracy: 38.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 38.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:36<00:00,  4.97it/s]\n",
      "  0%|          | 1/1973 [00:00<06:15,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  38  , train loss :  1.4687791605837044 , train_accuracy: 54.62  , valid loss : 2.522684846056832 , val_accuracy: 38.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:13<00:00,  5.28it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  39  , train loss :  1.43697383988681 , train_accuracy: 55.62  , valid loss : 2.497762788799074 , val_accuracy: 38.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:24<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  40  , train loss :  1.3882030402687053 , train_accuracy: 56.95  , valid loss : 2.586329621473948 , val_accuracy: 39.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 39.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:35<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  41  , train loss :  1.3393697275076766 , train_accuracy: 58.03  , valid loss : 2.425975351995892 , val_accuracy: 42.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 42.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:25<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  42  , train loss :  1.3336233568248945 , train_accuracy: 57.89  , valid loss : 2.4552696969111762 , val_accuracy: 43.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 43.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:31<00:00,  5.04it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  43  , train loss :  1.2947553227372222 , train_accuracy: 59.85  , valid loss : 2.4615666131178537 , val_accuracy: 43.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:43<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  44  , train loss :  1.2418294906771088 , train_accuracy: 60.76  , valid loss : 2.3766355173455342 , val_accuracy: 44.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, current best val_accuracy: 44.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:34<00:00,  5.00it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  45  , train loss :  1.1857181183473942 , train_accuracy: 62.8  , valid loss : 2.501040957503849 , val_accuracy: 43.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:39<00:00,  4.93it/s]\n",
      "  0%|          | 0/1973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  46  , train loss :  1.1733848714459811 , train_accuracy: 63.0  , valid loss : 2.4356797742181353 , val_accuracy: 43.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [06:32<00:00,  5.03it/s]\n",
      "  0%|          | 1/1973 [00:00<06:08,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  47  , train loss :  1.1408546399734751 , train_accuracy: 63.83  , valid loss : 2.4262655148241254 , val_accuracy: 44.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:46<00:00,  5.70it/s]\n",
      "  0%|          | 1/1973 [00:00<05:41,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  48  , train loss :  1.1016402352716739 , train_accuracy: 65.0  , valid loss : 2.5625516823265286 , val_accuracy: 44.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1973/1973 [05:40<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  49  , train loss :  1.0716851581558768 , train_accuracy: 65.82  , valid loss : 2.5937047643793956 , val_accuracy: 44.47\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# training and testing\n",
    "writer = SummaryWriter(run_logdir)\n",
    "Max_val_accuracy=0\n",
    "no_improve_count=0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss=0.0\n",
    "    val_loss=0.0\n",
    "    #train_accuracy=0.0\n",
    "    #val_accuracy=0.0\n",
    "    train_correct = 0.\n",
    "    train_total = 0.\n",
    "    val_correct = 0.\n",
    "    val_total = 0.\n",
    "    \n",
    "    for step, (x, y) in enumerate(tqdm(train_loader)):   #  batch data, normalize x when iterate train_loader\n",
    "        b_x=Variable(x).cuda()\n",
    "        b_y=Variable(y).cuda()\n",
    "        \n",
    "        output = model(b_x)               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        #print(\"loss:\",loss)\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()               # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        train_loss+=loss.item()*x.size(0)\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "        # compare predictions to true label\n",
    "        train_correct += np.sum(np.squeeze(pred.eq(y.data.view_as(pred))).cpu().numpy())\n",
    "        train_total += x.size(0)\n",
    "    \n",
    "    for step, (x, y) in enumerate(valid_loader):  #  loader \n",
    "        # ...\n",
    "        b_x=Variable(x).cuda()\n",
    "        b_y=Variable(y).cuda()\n",
    "        # \n",
    "        output = model(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "        val_loss+=loss.item()*x.size(0)\n",
    "         \n",
    "        pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "        # compare predictions to true label\n",
    "        \n",
    "        val_correct += np.sum(np.squeeze(pred.eq(y.data.view_as(pred))).cpu().numpy())\n",
    "        val_total += x.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    val_loss=val_loss/len(valid_loader.dataset)\n",
    "    train_accuracy=round((100. *train_correct / train_total),2)\n",
    "    val_accuracy=round((100. *val_correct / val_total),2)\n",
    "    writer.add_scalars('loss', {'train_loss':train_loss,'valid_loss':val_loss}, epoch)\n",
    "    writer.add_scalars('accuracy', {'train_accuracy':train_accuracy,'valid_accuracy':val_accuracy}, epoch)\n",
    "    print('epoch ',epoch,' , train loss : ',train_loss,', train_accuracy:',train_accuracy,' , valid loss :',val_loss,', val_accuracy:',val_accuracy)\n",
    "    \n",
    "    if(val_accuracy>Max_val_accuracy):\n",
    "        Max_val_accuracy=val_accuracy\n",
    "        no_improve_count=0\n",
    "        torch.save(model.state_dict(), run_logdir+'_weights.pkl')\n",
    "        print(\"save model, current best val_accuracy:\",Max_val_accuracy)\n",
    "    else:\n",
    "        no_improve_count+=1\n",
    "    if(no_improve_count>=EARLY_STOP_Threshold):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "cnn = make_model('xception', num_classes=120, pretrained=True, input_size=(299, 299), classifier_factory=make_classifier)\n",
    "cnn.load_state_dict(torch.load(run_logdir+'_weights.pkl'))\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(cnn, model_name+'.pkl')\n",
    "torch.save(cnn.state_dict(), model_name+'_weights.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "cnn = make_model('xception', num_classes=120, pretrained=True, input_size=(299, 299), classifier_factory=make_classifier)\n",
    "cnn.load_state_dict(torch.load('run_2021_01_07-15_10_01_weights_61.pkl'))\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}'.format(test_loss))\n",
    "\n",
    "    print('Test Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(IMAGE_SIZE),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder('data/test', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "cnn=cnn.cuda()\n",
    "test(test_loader, cnn, loss_func, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(train_loader, cnn, loss_func, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_yolo",
   "language": "python",
   "name": "python_yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
