{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from ModelDefine import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class name\n",
    "train_data = datasets.ImageFolder('data/train')\n",
    "class_dir=train_data.class_to_idx\n",
    "class_list=list(class_dir.keys())\n",
    "#print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN:\n\tUnexpected key(s) in state_dict: \"batchNorm.weight\", \"batchNorm.bias\", \"batchNorm.running_mean\", \"batchNorm.running_var\", \"batchNorm.num_batches_tracked\", \"conv1.2.weight\", \"conv1.2.bias\", \"conv1.2.running_mean\", \"conv1.2.running_var\", \"conv1.2.num_batches_tracked\", \"conv2.5.weight\", \"conv2.5.bias\", \"conv2.5.running_mean\", \"conv2.5.running_var\", \"conv2.5.num_batches_tracked\", \"conv2.2.bias\", \"conv2.2.running_mean\", \"conv2.2.running_var\", \"conv2.2.num_batches_tracked\", \"conv2.3.weight\". \n\tsize mismatch for conv2.2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-28c10c653d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run_2021_01_07-00_19_55_weights_20.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python_yolo/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN:\n\tUnexpected key(s) in state_dict: \"batchNorm.weight\", \"batchNorm.bias\", \"batchNorm.running_mean\", \"batchNorm.running_var\", \"batchNorm.num_batches_tracked\", \"conv1.2.weight\", \"conv1.2.bias\", \"conv1.2.running_mean\", \"conv1.2.running_var\", \"conv1.2.num_batches_tracked\", \"conv2.5.weight\", \"conv2.5.bias\", \"conv2.5.running_mean\", \"conv2.5.running_var\", \"conv2.5.num_batches_tracked\", \"conv2.2.bias\", \"conv2.2.running_mean\", \"conv2.2.running_var\", \"conv2.2.num_batches_tracked\", \"conv2.3.weight\". \n\tsize mismatch for conv2.2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3])."
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn.load_state_dict(torch.load('run_2021_01_07-00_19_55_weights_20.pkl'))\n",
    "cnn.eval()\n",
    "cnn=cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"data/predict_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02110958-pug\n",
      "n02110958-pug\n",
      "n02108551-Tibetan_mastiff\n",
      "n02110958-pug\n",
      "n02110958-pug\n",
      "n02087046-toy_terrier\n",
      "n02108551-Tibetan_mastiff\n",
      "n02102040-English_springer\n",
      "n02110958-pug\n",
      "n02088094-Afghan_hound\n"
     ]
    }
   ],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "preprocess = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "from PIL import Image\n",
    "for img_name in images:\n",
    "    # An instance of your model.\n",
    "    img_pil = Image.open(image_path+\"/\"+img_name)\n",
    "    #img_pil.show()\n",
    "    img_tensor = preprocess(img_pil).float()\n",
    "    img_tensor = img_tensor.unsqueeze_(0)\n",
    "    img_tensor=img_tensor.cuda()\n",
    "    fc_out = cnn(Variable(img_tensor))\n",
    "\n",
    "    output = fc_out.detach().cpu().numpy()\n",
    "    print(class_list[output.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_yolo",
   "language": "python",
   "name": "python_yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
